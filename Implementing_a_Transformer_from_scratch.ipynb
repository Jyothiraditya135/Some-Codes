{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWWi92+QQU+n7/tYgqy2jC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jyothiraditya135/Some-Codes/blob/main/Implementing_a_Transformer_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY1xULGaNIlD",
        "outputId": "d2a8b192-bf5a-44d7-8dd8-9478284abe8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Ycz13hbUbC"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "import math\n",
        "import copy\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Seeding for reproducible results everytime\n",
        "SEED = 777\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3O84xSeNNKjI",
        "outputId": "09d27adc-0bbc-4448-9faf-bda38102d635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Seeding for reproducible results everytime\\nSEED = 777\\n\\nrandom.seed(SEED)\\nnp.random.seed(SEED)\\ntorch.manual_seed(SEED)\\ntorch.cuda.manual_seed(SEED)\\ntorch.backends.cudnn.deterministic = True'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrNraUABrDq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "136ec479-e4df-4def-e83d-70530b7a31db"
      },
      "source": [
        "\n",
        "!python -m spacy download en_core_web_sm --quiet\n",
        "!python -m spacy download de_core_news_sm --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-23 11:26:34.016168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2023-07-23 11:26:52.409556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Da1d8Pb-p4"
      },
      "source": [
        "spacy_de = spacy.load(\"de_core_news_sm\")\n",
        "spacy_en = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leVROD_6qz16"
      },
      "source": [
        "def tokenize_de(text):\n",
        "  return [token.text for token in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "  return [token.text for token in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn8CDZ1ssIju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b34ef0-66fd-424d-b0c7-b802229cedf1"
      },
      "source": [
        "DE_TEXT = Field(tokenize=tokenize_de, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\", unk_token=\"<unk>\")\n",
        "EN_TEXT = Field(tokenize=tokenize_en, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\", unk_token=\"<unk>\")\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = (\".de\", \".en\"),\n",
        "                                                    fields=(DE_TEXT, EN_TEXT))\n",
        "\n",
        "DE_TEXT.build_vocab(train_data, max_size=10001, min_freq=3)\n",
        "EN_TEXT.build_vocab(train_data, max_size=10001, min_freq=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading training.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 6.86MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading validation.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 1.86MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 1.66MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \"<pad>\" in EN_TEXT.vocab.stoi:\n",
        "  print('Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOTTScp7S9Hl",
        "outputId": "e1c7ad5d-e8a1-4afd-eb9c-9cb1dbb298b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \"<pad>\" in DE_TEXT.vocab.stoi:\n",
        "  print('Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSTcLsOoTFJe",
        "outputId": "ad2ba2bc-1eed-42cc-ab8a-daae6bb0ec72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(EN_TEXT.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMjg5wqIygQs",
        "outputId": "906fa451-b1e5-4054-9d45-91c104094ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4556"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(EN_TEXT.vocab.stoi.values()))\n",
        "print(max(EN_TEXT.vocab.stoi.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfja51jdzQt8",
        "outputId": "a935bee9-52c4-476a-d88a-b55253a5dc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "4555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(DE_TEXT.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlLWuelGzghk",
        "outputId": "256e337f-f4bf-422b-eb35-b0680cea6944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5374"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(DE_TEXT.vocab.stoi.values()))\n",
        "print(max(DE_TEXT.vocab.stoi.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9UHWO_zzgfL",
        "outputId": "b651fe40-3263-4e20-c6e1-84ee04429eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "5373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gmz5adIwbwF"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_iter, valid_iter, test_iter = BucketIterator.splits((train_data, valid_data, test_data),\n",
        "                                                                      batch_size = BATCH_SIZE,\n",
        "                                                                      sort_within_batch=True,\n",
        "                                                                      sort_key=lambda x: len(x.src),\n",
        "                                                                      device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have an iterator named `train_iter` for your training data\n",
        "batch = next(iter(train_iter))\n",
        "\n",
        "# Access tokenized sequences for source and target languages\n",
        "source_tokens = batch.src\n",
        "target_tokens = batch.trg\n",
        "\n",
        "# Print the tokenized sequences for the first batch\n",
        "print(\"Source Tokens:\")\n",
        "print(source_tokens)\n",
        "print(\"Target Tokens:\")\n",
        "print(target_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1s2RgY5AQfK",
        "outputId": "c17da828-f6e5-47ef-ef3b-031b9342b547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Tokens:\n",
            "tensor([[   2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
            "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
            "            2,    2,    2,    2,    2,    2,    2,    2],\n",
            "        [   8,    5,   15,    8,    5,  221,   18,    5,    5,    5,   18,   43,\n",
            "            5,  325,    8,    8,    5,    5,    5,   18,   18,    5,    8,    5,\n",
            "           65,    5,    5,    5,    8,    5,    8,   18],\n",
            "        [  16,  777, 1611,  165,  130,   30,   80, 2859,  385,   32,   30,   54,\n",
            "           13,   29,   26,  113,  431,   13,   26,   26,  103,   13,   36,   13,\n",
            "         2120,   13,   66,   32,   36,   66,  364, 5071],\n",
            "        [  98,  580,   32,  350,   13,   10,   52,  116,   25,   83,   52,   57,\n",
            "           31, 1400,   16,    9,   68,   11,   11,  330,   80,    7,   22,    7,\n",
            "          125,   11,   25,  443,   22,   25,   10,   12],\n",
            "        [  14,  182,   83,   11,   11,   45,   12,    9,    9,   21,    7,   20,\n",
            "           21, 1703,  204,   17,    7,    6,  138,   84,    7,    6, 4428,  114,\n",
            "         5297,  192,    7,   21,  245,    7,  125,   14],\n",
            "        [   0,  109,   58,   18, 2723,   52,   24,   39,   39,   14,    6,  123,\n",
            "            6,    7,   10,   23,   14,  175,   10,  131,  657,  257,  267,   97,\n",
            "           56,   31,    6,    6,   31,    6,   18, 1978],\n",
            "        [   0,  157,   19,   80,  188,    7,  222,  139,    5, 1038, 1969,   11,\n",
            "          107,   15,   38,    7,  152,  607, 1342,   11,    0,   79,   55,   10,\n",
            "            6,   47,  648,   91,   21,  199,    0,    9],\n",
            "        [ 169,   19,   22,   17,  566, 1377,   47, 1339,  518,   12,   47,    6,\n",
            "           12,  436,  129,    6, 1146,    9,   40,  357,   12,   69,    0,   14,\n",
            "          575,    6,  475,    8,   19,   79,    7,   17],\n",
            "        [  10,   94, 1454,  470,   23,   97,    6,   20, 4480,   14,  463,  240,\n",
            "           24,   44,   59,  643,   12,  801,  184,  294,    6,   22,  111,    0,\n",
            "          437,  107,   11,  349,   50,  342,    6, 4031],\n",
            "        [ 184,  580, 2436,    0, 1483,   20, 5227,   88,    0,  247,  382,   20,\n",
            "            0,   78,   14, 5350,    6, 2394,    5,   20,   78,   14,   28,   38,\n",
            "           14,  266,  332, 1868, 2628,   12, 2885,    0],\n",
            "        [ 393,   21,  295,  163,   21,   88,  268,  404,  944,  117,  294,   86,\n",
            "           29,  362, 2443,   93,   87, 2159,  286,   86,  135,  439,   10,  129,\n",
            "          439, 1029, 1160, 1699, 1135,  424,    4,    4],\n",
            "        [   4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
            "            4,    4,    4,    4,    4,    4,    4,    4,    4,    4,  892,    4,\n",
            "            4,    4,    4,    4,    4,    4,    3,    3],\n",
            "        [   3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3,    3,    1,    1]], device='cuda:0')\n",
            "Target Tokens:\n",
            "tensor([[   2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
            "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
            "            2,    2,    2,    2,    2,    2,    2,    2],\n",
            "        [   4,   46,    7,    4,   21,   74,   16,    4,    4,    4,   16,   48,\n",
            "            9,  290,    4,    4,    4,    4,    4,   16,   16,    4,    4,    4,\n",
            "           63,    4,   21,    4,    4,    4,    4,   16],\n",
            "        [  14,  161,   61,  120,  115,   30,  127,  667,  122,   35,   30,   19,\n",
            "           13,  949,   24,   87,   64,    9,   34,   24,   24,    9,   38,    9,\n",
            "         1780,    9,  153,   35,   38,   24,  496,    0],\n",
            "        [  10,  674,   35,   10,    9,   11,   17,  154,   33,   79,   36,  128,\n",
            "            0,    4,   14,   12,   10,    6,   13,  326,  127,    6,   12,   13,\n",
            "           47,   22,   33, 3396,   12,   33,   11,    8],\n",
            "        [ 133,  107,   10,  256,   13,   74,   36,  304,  914,  124,    6,    6,\n",
            "            8, 2665,  269,   19,  169,   21,  146,   57,   22,    4, 2963,    4,\n",
            "         1632,  217,    6,    4,  196,    6,   44,    4],\n",
            "        [  11,   20,   41,   13, 1843,   50,    8,   66,    4,  344,    4,    7,\n",
            "            4,    6,   11,  129,  901,   86,   11,   15,  555,  194, 4161,  647,\n",
            "           65,   32,    4,   31,   32,    4,   16,  664],\n",
            "        [ 218,   82,   60,   16,   97,   17,  211,  310,   52,    4, 1480,   95,\n",
            "           94,    7,   37,    6,    8,  325,  384,   13,    0,   23,   15,  630,\n",
            "            4,   71, 1119, 2473,  236,   90, 3373,  142],\n",
            "        [   4,   58,    4,   24,   10,   36,   71,  103, 1043,  928, 1028,   13,\n",
            "            5,  168,  126,   46,    4,   67,   23,  202,    6,   10,  370,   15,\n",
            "          565,   18,   90,    8,    4,   23,  621,  656],\n",
            "        [ 556,  244,  309,  127, 1021,   57,   18,  624, 2348,    6,   71,    4,\n",
            "            3,   12,    6,  177,  157, 1201,  455,  250,    4,   92,   11,   73,\n",
            "           80,    4,  300,    4,   59, 2707,    6, 1172],\n",
            "        [  93,  164,  334,  405,   75,   28,   21,    5,    5,    4,   18,  397,\n",
            "            1,    4,    4,    5,    6,  978,    4,    6,   59,  111, 2940,  255,\n",
            "            4,   94, 2282,   88,   31,    4,    4,    5],\n",
            "        [   4,    5,   49,   22, 3116,   22, 3544,    3,    3,  287,  113,    6,\n",
            "            1,   59,  789,    3,    4, 1280,  277,    7,   85,    4,  131,    6,\n",
            "          308,  298,    5,    5, 2135,  321, 1077,    3],\n",
            "        [   0,    3, 1312,   52,    5,  263,  243,    1,    1,   85,  404,    7,\n",
            "            1,   77,    5,    1,  101,    5,    5,   98,    5,  308,    3,   26,\n",
            "           42,   12,    3,    3,    5,    8,    5,    1],\n",
            "        [ 299,    1,    5,   47,    3,  219,    5,    1,    1,    5,  250,   98,\n",
            "            1,    5,    3,    1,    5,    3,    3,    5,    3,    5,    1,   15,\n",
            "          363, 1762,    1,    1,    3,  311,    3,    1],\n",
            "        [1147,    1,    3, 1751,    1,    5,    3,    1,    1,    3,    5,    5,\n",
            "            1,    3,    1,    1,    3,    1,    1,    3,    1,    3,    1,  137,\n",
            "            5,    5,    1,    1,    1,    5,    1,    1],\n",
            "        [   5,    1,    1,    5,    1,    3,    1,    1,    1,    1,    3,    3,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,  126,\n",
            "            3,    3,    1,    1,    1,    3,    1,    1],\n",
            "        [   3,    1,    1,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    5,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    3,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"<pad> token index:\", DE_TEXT.vocab.stoi['<pad>'])\n",
        "print(\"<sos> token index:\", DE_TEXT.vocab.stoi['<sos>'])\n",
        "print(\"<eos> token index:\", DE_TEXT.vocab.stoi['<eos>'])\n",
        "print(\"<unk> token index:\", DE_TEXT.vocab.stoi['<unk>'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffNcVGhKiHWw",
        "outputId": "0ea9b6e6-95e1-480d-f429-4c0584c6b97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> token index: 1\n",
            "<sos> token index: 2\n",
            "<eos> token index: 3\n",
            "<unk> token index: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"<pad> token index:\", EN_TEXT.vocab.stoi['<pad>'])\n",
        "print(\"<sos> token index:\", EN_TEXT.vocab.stoi['<sos>'])\n",
        "print(\"<eos> token index:\", EN_TEXT.vocab.stoi['<eos>'])\n",
        "print(\"<unk> token index:\", EN_TEXT.vocab.stoi['<unk>'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnNwnWkqiJNp",
        "outputId": "6a6a5017-f818-45e5-8c29-4ebc6eb4eb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> token index: 1\n",
            "<sos> token index: 2\n",
            "<eos> token index: 3\n",
            "<unk> token index: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#class Embedder(nn.Module):\n",
        "#  def __init__(self, vocab_size, d_model):\n",
        "#    super().__init__()\n",
        "#    self.embed = nn.Embedding(vocab_size, d_model, padding_idx = 0)\n",
        "#  def forward(self, x):\n",
        "#    try:\n",
        "#      return self.embed(x)\n",
        "#    except:\n",
        "#      print(x)"
      ],
      "metadata": {
        "id": "YhrLqrNm2mAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        try:\n",
        "            return self.embed(x)\n",
        "        except IndexError as e:\n",
        "            print(\"Caught an IndexError while embedding the input:\")\n",
        "            print(f\"Input tensor shape: {x.shape}\")\n",
        "            print(f\"Maximum token index in the input tensor: {torch.max(x)}\")\n",
        "            print(f\"Vocabulary size: {self.embed.num_embeddings}\")\n",
        "            print(f\"Embedding matrix shape: {self.embed.weight.shape}\")\n",
        "            raise e"
      ],
      "metadata": {
        "id": "_wiQToYpd9l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Positional_Embedder(nn.Module):\n",
        "  def __init__(self, d_model, max_seq_l=100):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "\n",
        "    pe = torch.zeros(max_seq_l, d_model)\n",
        "    for pos in range(max_seq_l):\n",
        "      for i in range(0, d_model, 2):\n",
        "        pe[pos, i] = math.sin( pos / (10000 ** ( (2*i) / d_model)))\n",
        "        pe[pos, i+1] = math.cos( pos / (10000 ** ( (2*(i+1)) / d_model)))\n",
        "\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x * math.sqrt(self.d_model)\n",
        "    seq_len = x.size(1)\n",
        "    x = x + self.pe[:, :seq_len].detach().to(x.device)\n",
        "    return x"
      ],
      "metadata": {
        "id": "KtmM9gH73Kr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_iter))\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N2waE0NPWV5",
        "outputId": "2529aabd-bc35-47de-b3e1-ae27ce27ddd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[torchtext.data.batch.Batch of size 32 from MULTI30K]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 18x32 (GPU 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_pad = EN_TEXT.vocab.stoi['<pad>']\n",
        "target_pad = DE_TEXT.vocab.stoi['<pad>']"
      ],
      "metadata": {
        "id": "qvvjIiySuzzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(src, trg):\n",
        "\n",
        "\n",
        "    # creates mask with 0s wherever there is padding in the input\n",
        "    src_mask = (src != input_pad).unsqueeze(1)\n",
        "\n",
        "    if trg is not None:\n",
        "        trg_mask = (trg != target_pad).unsqueeze(1)\n",
        "        size = trg.size(1)  # get seq_len for matrix\n",
        "        np_mask = nopeak_mask(size)\n",
        "        trg_mask = trg_mask & np_mask\n",
        "\n",
        "    else:\n",
        "        trg_mask = None\n",
        "\n",
        "    return src_mask, trg_mask"
      ],
      "metadata": {
        "id": "9SiTDpInr-BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nopeak_mask(size):\n",
        "    np_mask = np.triu(np.ones((1, size, size), dtype=np.uint8), k=1)\n",
        "    np_mask = torch.tensor(np_mask == 0, dtype=torch.bool)\n",
        "    return np_mask"
      ],
      "metadata": {
        "id": "vMHPXCD9so03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, heads, d_model, dropout=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_k = d_model // heads\n",
        "    self.h = heads\n",
        "\n",
        "    self.q_lin = nn.Linear(d_model, d_model)\n",
        "    self.k_lin = nn.Linear(d_model, d_model)\n",
        "    self.v_lin = nn.Linear(d_model, d_model)\n",
        "    self.drop = nn.Dropout(dropout)\n",
        "    self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "  def forward(self, q, k, v, mask=None):\n",
        "    bs = q.size(0)\n",
        "    q = self.q_lin(q).view(bs, -1, self.h, self.d_k)\n",
        "    k = self.k_lin(k).view(bs, -1, self.h, self.d_k)\n",
        "    v = self.v_lin(v).view(bs, -1, self.h, self.d_k)\n",
        "\n",
        "    q = q.transpose(1, 2)\n",
        "    k = k.transpose(1, 2)\n",
        "    v = v.transpose(1, 2)\n",
        "\n",
        "    scores = attention(q, k, v, self.d_k, mask, self.drop)\n",
        "    concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
        "    output = self.out(concat)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "M-wqaEVOJC9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(q, k, v, d_k, mask=None, drop=None):\n",
        "  scores = torch.matmul(q, k.transpose(-2,-1))\n",
        "  if mask is not None:\n",
        "    mask = mask.unsqueeze(1)\n",
        "    scores = scores.masked_fill(mask == 0, -1e9)\n",
        "  scores = F.softmax(scores, dim=-1)\n",
        "\n",
        "  if drop is not None:\n",
        "    scores = drop(scores)\n",
        "\n",
        "  output = torch.matmul(scores, v)\n",
        "  return output"
      ],
      "metadata": {
        "id": "pWLFJOzLLk-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.lin_1 = nn.Linear(d_model, d_ff)\n",
        "    self.drop = nn.Dropout(dropout)\n",
        "    self.lin_2 = nn.Linear(d_ff, d_model)\n",
        "  def forward(self, x):\n",
        "    y = self.drop(F.relu(self.lin_1(x)))\n",
        "    z = self.lin_2(y)\n",
        "    return z"
      ],
      "metadata": {
        "id": "gRwHCvG4XZ4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Norm(nn.Module):\n",
        "  def __init__(self, d_model, eps = 1e-6):\n",
        "    super().__init__()\n",
        "\n",
        "    self.size = d_model\n",
        "    self.alpha = nn.Parameter(torch.ones(self.size))\n",
        "    self.bias = nn.Parameter(torch.zeros(self.size))\n",
        "    self.eps = eps\n",
        "\n",
        "  def forward(self, x):\n",
        "    norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) +self.eps) + self.bias\n",
        "    return norm"
      ],
      "metadata": {
        "id": "QEhGxq6hYqGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, heads, drop=0.1):\n",
        "    super().__init__()\n",
        "    self.norm_mha = Norm(d_model)\n",
        "    self.norm_ffn = Norm(d_model)\n",
        "    self.attn = MultiHeadAttention(heads, d_model)\n",
        "    self.ff = FeedForward(d_model)\n",
        "    self.drop_mha = nn.Dropout(drop)\n",
        "    self.drop_ffn = nn.Dropout(drop)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    y = self.norm_mha(x)\n",
        "    x = x + self.drop_mha(self.attn(y, y, y, mask))\n",
        "    z = self.norm_ffn(x)\n",
        "    op = x + self.drop_ffn(self.ff(z))\n",
        "    return op"
      ],
      "metadata": {
        "id": "nSJnRIlEZofE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, heads, drop=0.1):\n",
        "    super().__init__()\n",
        "    self.norm_mmha = Norm(d_model)\n",
        "    self.norm_mha = Norm(d_model)\n",
        "    self.norm_ffn = Norm(d_model)\n",
        "    self.drop_mmha = nn.Dropout(drop)\n",
        "    self.drop_mha = nn.Dropout(drop)\n",
        "    self.drop_ffn = nn.Dropout(drop)\n",
        "    self.mmh_attn = MultiHeadAttention(heads, d_model)\n",
        "    self.mh_attn = MultiHeadAttention(heads, d_model)\n",
        "    self.ff = FeedForward(d_model)\n",
        "\n",
        "  def forward(self, x, e_op, src_mask, trg_mask):\n",
        "    y = self.norm_mmha(x)\n",
        "    x = x + self.drop_mmha(self.mmh_attn(y, y, y, trg_mask))\n",
        "    z = self.norm_mha(x)\n",
        "    x = x + self.drop_mha(self.mh_attn(z, e_op, e_op, src_mask))\n",
        "    w = self.norm_ffn(x)\n",
        "    op = x + self.drop_ffn(self.ff(w))\n",
        "    return op"
      ],
      "metadata": {
        "id": "dfkcBKtuKYXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ],
      "metadata": {
        "id": "-D9OCdiKsoY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model, N, heads):\n",
        "    super().__init__()\n",
        "    self.N = N\n",
        "    self.embed = Embedder(vocab_size, d_model)\n",
        "    self.pe = Positional_Embedder(d_model)\n",
        "    self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
        "    self.norm = Norm(d_model)\n",
        "  def forward(self, src, mask):\n",
        "    x = self.embed(src)\n",
        "    x_emb = self.pe(x)\n",
        "    for i in range(N):\n",
        "      op = self.layers[i](x_emb, mask)\n",
        "    return self.norm(op)"
      ],
      "metadata": {
        "id": "gNwnotsPMDhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model, N, heads):\n",
        "    super().__init__()\n",
        "    self.N = N\n",
        "    self.embed = Embedder(vocab_size, d_model)\n",
        "    self.pe = Positional_Embedder(d_model)\n",
        "    self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
        "    self.norm = Norm(d_model)\n",
        "  def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
        "    x = self.embed(trg)\n",
        "    x_emb = self.pe(x)\n",
        "    for i in range(self.N):\n",
        "        op = self.layers[i](x_emb, e_outputs, src_mask, trg_mask)\n",
        "    return self.norm(op)"
      ],
      "metadata": {
        "id": "wR-xW6JpsoeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
        "    self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
        "    self.out = nn.Linear(d_model, trg_vocab)\n",
        "  def forward(self, src, trg, src_mask, trg_mask):\n",
        "    e_op = self.encoder(src, src_mask)\n",
        "    d_op = self.decoder(trg, e_op, src_mask, trg_mask)\n",
        "    op = self.out(d_op).to(src.device)\n",
        "    return op"
      ],
      "metadata": {
        "id": "7nwfHw9FWSZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters (according to the paper)"
      ],
      "metadata": {
        "id": "BlTT41KJXnDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "heads = 8\n",
        "N = 6\n",
        "src_vocab = len(DE_TEXT.vocab)\n",
        "trg_vocab = len(EN_TEXT.vocab)"
      ],
      "metadata": {
        "id": "H-xiT9zJsoWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(src_vocab, trg_vocab, d_model, N, heads)"
      ],
      "metadata": {
        "id": "28P45gTMsoS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "fWA73dPDZ8XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "# this code is very important! It initialises the parameters with a\n",
        "# range of values that stops the signal fading or getting too big.\n",
        "# See this blog for a mathematical explanation.\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "metadata": {
        "id": "b6wY0Jw3soP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = batch.src.transpose(0,1)\n",
        "trg = batch.trg.transpose(0,1)\n",
        "trg_input = trg[:, :-1]\n",
        "targets = trg[:, 1:].contiguous().view(-1)\n",
        "src_mask, trg_mask = create_masks(src, trg_input)\n",
        "src_embedder = Embedder(vocab_size=src_vocab, d_model=d_model)\n",
        "print(src_embedder.state_dict()['embed.weight'].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "tUyxsh0cQpHp",
        "outputId": "ba98774d-b5f8-4a63-f920-ebaabe44f0f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-ce86c91d0b55>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msrc_embedder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embed.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-2e2de13a0ce6>\u001b[0m in \u001b[0;36mcreate_masks\u001b[0;34m(src, trg)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get seq_len for matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnp_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnopeak_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg_mask\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mnp_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(train_iter):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "hrgSTt5PlvO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs, print_every=100):\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for i, batch in enumerate(train_iter):\n",
        "            src = batch.src.transpose(0,1)\n",
        "            trg = batch.trg.transpose(0,1)\n",
        "\n",
        "            trg_input = trg[:, :-1]\n",
        "            targets = trg[:, 1:].contiguous().view(-1)\n",
        "            src_mask, trg_mask = create_masks(src, trg_input)\n",
        "            preds = model(src, trg_input, src_mask, trg_mask)\n",
        "            optim.zero_grad()\n",
        "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), targets, ignore_index=target_pad)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            if (i + 1) % print_every == 0:\n",
        "                loss_avg = total_loss / print_every\n",
        "                print(\"epoch %d, iter = %d, loss = %.3f\" % (epoch + 1, i + 1, loss_avg))\n",
        "                total_loss = 0"
      ],
      "metadata": {
        "id": "O8Qk0th2ZYwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(10)"
      ],
      "metadata": {
        "id": "Ccux7cwEwfse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(model, src, max_len = 80, custom_sentence=False):\n",
        "    model.eval()\n",
        "    if custom_sentence == True:\n",
        "        src = tokenize_en(src)\n",
        "        sentence = torch.LongTensor([[EN_TEXT.vocab.stoi[tok] for tok in sentence]]).to(device)\n",
        "        src_mask = (src != input_pad).unsqueeze(-2)\n",
        "        e_outputs = model.encoder(src, src_mask)\n",
        "\n",
        "        outputs = torch.zeros(max_len).type_as(src.data)\n",
        "        outputs[0] = torch.LongTensor([DE_TEXT.vocab.stoi['<sos>']])\n",
        "        for i in range(1, max_len):\n",
        "          trg_mask = np.triu(np.ones((1, i, i), k=1)).astype('uint8')\n",
        "          trg_mask = torch.tensor(trg_mask == 0).to(device)\n",
        "          out = model.out(model.decoder(outputs[:i].unsqueeze(0), e_outputs, src_mask, trg_mask))\n",
        "          out = F.softmax(out, dim=-1)\n",
        "          val, ix = out[:, -1].data.topk(1)\n",
        "\n",
        "          outputs[i] = ix[0][0]\n",
        "          if ix[0][0] == DE_TEXT.vocab.stoi['<eos>']:\n",
        "            break\n",
        "\n",
        "        return ' '.join([DE_TEXT.vocab.itos[ix] for ix in outputs[:i]])"
      ],
      "metadata": {
        "id": "FYjheLuhZXDb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}